\section{\mbox{Data Source}}
\label{sec:data}
% Comcast dataset quick overview, dates, usage, tiers
Our dataset consists of network usage byte counters reported by Comcast gateways every 15 minutes from October 1, 2014 to December 29, 2014. There are two sets of broadband tiers that were used to collect this data: \control set, consisting of homes and businesses with a 105 Mbps access link, and the \test set, consisting of homes and businesses that were paying for a 105 Mbps access link, yet were receiving 250 Mbps instead. Users in the test set were selected randomly and were not told that their access bandwidth has been increased. There were more than 15000 gateway devices in the control set, with varying usage over the three months, and about 2200 gateway devices in the test set.
% test 2200 are unsanitized, after is 1481
% control ?? unsanitized. control4 itself has 15000 for the first 6 days that drops to 5k later. 16015 is after sanitization
\todo{confirm - these were reported by Comcast gateways right?}

% Representativeness of dataset
Both the \test and \control sets were collected from users in Salt Lake City, Utah, to avoid any biases in behavior based on location. Although this dataset corresponds to just one ISP, we believe that it is broadly representative of urban users in the US in the same, or higher broadband bandwidth tier ($\>$ 100 Mbps). Thus, we use this data to draw general conclusions about behavioral change with link capacity \todo{(add more here...) }

% use bismark passive data for passive patterns on different tiers - utilization like peeking paper
% active data for latency measurements to some central server during peak hours
\sg{Supplement the data with bismark?}

% mobile usage during peak vs non peak, user classification: wifi, 4g, tethering. Apps using most data
\sg{My Speed Test Usage Patterns data - Any chance?}

\subsection{Data Description}

%8 control sets, different devices, different times
%more details about data, fields, direction, locations?
Comcast splits the \control set into 8 separate pools on different date ranges and gateways \todo{confirm if there is repeated device IDs in control1-8.}. Each dataset contains the following relevant fields: Device ID, sample period time, service class, service direction, IP address, and the bytes transferred in the 15 minute sample slot ~\ref{tab:field-description}. \todo{find out more about service class name, and IP addresses being the same across all sets}

\begin{table}[ht]
\small
\begin{tabular}{|l|l|}
\hline
\textbf{Field}         & \textbf{Description}                      \\ \hline
Device\_number         & Arbitrarily assigned CM device identifier \\ \hline
end\_time              & Fifteen minute sample period end time     \\ \hline
date\_service\_created & Service start (not used in our analysis)  \\ \hline
service\_class\_name   & Used to differentiate data application    \\ \hline
cmts\_inet             & Cmts identifier (derived from ip address) \\ \hline
service\_direction     & 1-downstream, 2-upstream                  \\ \hline
port\_name             & Cmts port descriptor                      \\ \hline
octets\_passed         & Byte count                                \\ \hline
device\_key            & not used in our analysis                  \\ \hline
service\_identifier    & Service id (not used in our analysis)     \\ \hline
\end{tabular}
\caption{Field Descriptions for Comcast Dataset by Comcast}
\label{tab:field-description}
\end{table}

% split database by direction, combine service class name
To process the large amount of data (more than 15000 unique devices, 15 $\mult$ 24 time slots per day, 3 months, multiple service classes per time-slot), we first split the data by direction into uplink and downlink. The nature of the questions we ask in ~\ref{sec:background}


\sg{granularity of 15 mins, usually not perfectly synchronized but off by a very few seconds that shouldn't matter much when seeing larger aggregated patterns}

\subsection{Data Sanitization}

\sg{correlated drops at times or devices that contributed only 2-3 days of the whole month}

\sg{remove machines that contribute to less than 0.8 of the time slots.}

\todo{fig 1: Make common plot of availability -- 8 control sets (half filtered) vs availability.}

\sg{final table of set, num gateways, date range}

\sg{after sanitization, we can either compare test to each control in the same time range and draw agg conclusions, or do it by month, or combo it into a huge control set and compare it with test set}

\sg{Present results for full sets, unless there is a significant difference in any trends or distributions}