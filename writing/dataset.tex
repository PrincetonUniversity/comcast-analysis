\section{Data Source}
\label{sec:data}
% Comcast dataset quick overview, dates, usage, tiers
Our dataset consists of network usage byte counters reported by Comcast gateways 
every 15 minutes from October 1, 2014 to December 29, 2014. There are two sets 
of broadband tiers that were used to collect this data: \control set, consisting 
of households with a 105 Mbps access link, and the \test set, consisting of 
households that were paying for a 105 Mbps access link, yet were receiving 250 
Mbps instead. Users in the test set were selected randomly and were not told 
that their access bandwidth has been increased. There were more than 15000 
gateway devices in the control set, with varying usage over the three months, 
and about 2200 gateway devices in the test set.
% test 2200 are unsanitized, after is 1481
% control ?? unsanitized. control4 itself has 15000 for the first 6 days that drops to 5k later. 16015 is after sanitization
\todo{confirm - these were reported by Comcast gateways right?}


\subsection{Data Description}

%8 control sets, different devices, different times
%more details about data, fields, direction, locations?
The raw data sets provided by Comcast consisted of the \test set, and 8 separate 
\control sets consisting of more that 15k unique households, over different 
date ranges within the three months. Each dataset contains the following 
relevant fields: Device ID, sample period time, service class, service 
direction, IP address, and the bytes transferred in the 15 minute sample slot, 
as described in table~\ref{tab:field-description}.
%\todo{find out more about service class name, and IP addresses being the same across all sets}

\begin{table}[ht!]
\small
\begin{tabular}{|l|l|}
\hline
\textbf{Field}         & \textbf{Description}                      \\ \hline
Device\_number         & Arbitrarily assigned CM device identifier \\ \hline
end\_time              & Fifteen minute sample period end time     \\ \hline
cmts\_inet             & Cmts identifier (derived from ip address) \\ \hline
service\_direction     & 1-downstream, 2-upstream                  \\ \hline
octets\_passed         & Byte count                                \\ \hline
\end{tabular}
\caption{Field Descriptions for Comcast Dataset by Comcast}
\label{tab:field-description}
\end{table}

\subsection{Data Sanitization}

%\sg{correlated drops at times or devices that contributed only 2-3 days of the whole month}
Our initial analysis of data transferred per time slot showed that certain 
gateway devices were responsive only for brief periods. We also noticed that 
certain time slots had a very low response rate throughout the dataset. 
\todo{Why? asked comcast - waiting for response}.

%\sg{remove machines that contribute to less than 0.8 of the time slots.}
We evaluate the fraction of responsiveness of a gateway throughout the dataset, 
as well as the fraction of responsiveness per time slot, and call this the 
\textbf{heartbeat}. Figure~\ref{fig:availability} shows how the number of 
devices decreases for a higher heartbeat requirement. Based on the common 
trend of this plot throughout the \test and \control datasets, we decided to 
only choose gateway devices with an heartbeat of at least 0.8. 
%\sg{Furthermore, we also removed certain devices that were present only for 
%a few days}


\begin{figure}[ht!]
%\hspace*{-0.2in}
\begin{minipage}{1\linewidth}
\centering
%
%\hfill
\begin{subfigure}[b]{0.5\linewidth}
\includegraphics[width=\linewidth]{figures/250-test_dw-availability-CDF.png}
  \caption{Heartbeat by device}
  \label{fig:availability-device}
\end{subfigure}
%
\hspace{-1em}
%
\begin{subfigure}[b]{0.5\linewidth}
\includegraphics[width=\linewidth]{figures/250-test_dw-availability-by-date.png}
  \caption{Heartbeat by date}
  \label{fig:availability-date}
\end{subfigure}
%\hfill
%
\end{minipage}
\caption{Heartbeat, based on gateway device responsiveness. (Make common eps 
plot of heartbeat -- 8 control sets (half filtered) + test sets vs 
availability.) }
\label{fig:availability}
% created using docs/metadata-separated.log
\end{figure}


We sliced the sanitized \test set based on the date range of each 
individual \control set for comparison. We compared each of these tests 
individually to ensure that there are no outliers. We refer to the \test and 
\control sets in this case simply as datasets $set_1 - set_8$, where $set$ is 
\test or \control. We also sliced and combined the sanitized data to give us 
\control and \test data for each month, referred to as $set_{oct}$, $set_{nov}$, 
$set_{dec}$. Finally, we combine all \control sets to form a large concatenated 
dataset over the same date range as the complete \test dataset, and we refer to 
this simply as $set_{full}$. 

In the following analysis, we only present results for $set_{full}$, unless the 
behavior of an individual dataset varies significantly from the overall behavior 
and requires mention.

\subsection{Relevance of the Data}

In this section we describe how the Comcast database collected is both granular 
as well as unbiased. This database enables us to study usage behavior in a 
controlled setting. Beside, because of following properties, it is legitimized 
our use of it to compare and validate the \FCC policy.

% why only byte counters are okay for this work
\paragraph{Study Byte Counters:} The purpose of this work is to study the usage 
characteristics, irrespective of the application responsible for such usage. 
%This is bolstered by FCC's decision of net neutrality 
Limiting ourselves to just byte counters makes our analysis easily extendible 
to any ISP, and the FCC, interested in doing a similar study at a larger 
scale, without the risk of leaking PII. A study of applications has already 
been performed extensively by Sandvine ~\cite{}, as well as other researchers.


\paragraph{Granularity of 15 minutes:} Broadband usage evaluated by commercial 
groups ~\cite{}, or governmental survey bodies, usually employed by the FCC, 
tends to focus on aggregated usage statistics over months, long term trends, and 
applications. In our work we specifically focus on data transferred in 15 
minutes, to avoid short term bursts that max out the capacity, but account for 
long term heavy flows (such as real time entertainment and voip calls) that will 
continuously max out the access link. This gives us a granularity fine grained 
enough to study major changes in usage characteristics (such as peak trends) 
while ignoring short term bursts of traffic (such as browsing)

Note that byte counter readings collected every 15 minutes from multiple 
households were synchronized for consistency in measurements.

\paragraph{High Tier Measurements:} We limit ourselves to analyzing usage 
patterns in the high capacity access link tier only. The \test dataset was 
collected by increasing the capacity from 105 Mbps to to 250 Mbps for 2200 
randomly selected users, without their knowledge. This served a two-fold purpose 
in avoiding biases that studies on usage and capacity suffer from: (a) 
\emph{Avoid behavioral change bias:} offering users with high capacity a further 
increase without their knowledge avoids the risk of behavioral changes that may 
occur when one purposefully buys a higher bandwidth connection; and (b) 
\emph{Avoid frustrated user bias:} users already have a high capacity that gets 
upgraded, instead of opting for an upgrade because their previous capacity was 
insufficient for their usage. Studying datasets with these biases will always 
show a positive correlation between usage and capacity, and by examining a 
single high capacity tier, we avoid this.


\paragraph{Single ISP, Same Location:} No bias between service plans, pricing 
model, and traffic treatment. Controlled setting. Paths + performance should be 
similar and unbiased by the ISP as data is from one city. Also avoids local 
behavioral biases (if any).
This gives us a highly controlled setting to study usage behaviors in an 
unbiased manner across a very large set of users (15k \control and 1500 \test 
households). Thus we believe that are conclusions will be representative of 
broadband behavior in a general American urban city. We expect the baseline 
behavior of all users to be similar, and in fact, interpret any differences 
between the \control and \test set behavior as aggregate changes that occurred 
due to the an increase in access link capacity.


%explain that due to no bias in city, and large number of users, this can be 
%interpreted as change or no change in behavior due to increase in capacity of 
%the link. We expect the baseline behavior of these users to be exactly the 
%same. 
%Thus we will put our questions as "change in behavior due to increase in 
%capacity" rather than analysis of two different datasets as we have attempted 
%to 
%eliminate all biases.


%final datasets for each control, each month, and full
%\sg{after sanitization, we can either compare test to each control in the same 
%time range and draw agg conclusions, or do it by month, or combo it into a 
%huge control set and compare it with test set}
%\sg{Present results for full sets, unless there is a significant difference in 
%any trends or distributions}

% not telling users that the connection was upgraded lets us study correlation 
%between usage and capacity without the bias of user changing his behavior due 
%to external factors (buying a device, being more aggressive as they bought a 
%new plan)
% DASU supports correlation by measuring usage on each ISP tier, even for those 
%who changed tiers, but that is biased by user buying a higher tier when they 
%feel unsatisfied. It does not have a good representation of the case when the 
%ISP offers extra bandwidth without charging. Even if it does, the user knows 
%about the capacity bump inducing a change in behavior. Our dataset is unbiased 
%in that manner, we don't expect users to know they have a higher capacity and 
%still study if there is change in behavior


%Both the \test and \control sets were collected from users in Salt Lake City, 
%Utah, to avoid any biases in behavior based on location. Although this dataset 
%corresponds to just one ISP, we believe that it is broadly representative of 
%urban users in the US in the same, or higher broadband bandwidth tier ($\>$ 
%100 Mbps). Thus, we use this data to draw general conclusions about behavioral 
%change with link capacity \todo{(add more here...) }
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%A description of these sanitized sets is provided in table~\ref{tab:sanitized-description} 

%\begin{table*}[ht]
%\small
%\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|l|l|}
%\hline
%\textbf{Dataset}            & set$_1$      & set$_2$      & set$_3$      & set$_4$      & set$_5$      & set$_6$      & set$_7$      & set$_8$      & set$_{oct}$  & set$_{nov}$  & set$_{dec}$  & set$_{full}$ \\ \hline
%\textbf{Start Time}         & 2014-09-30  & 2014-10-01  & 2014-10-01  & 2014-11-01  & 2014-11-01  & 2014-11-01  & 2014-11-01  & 2014-12-01  & 2014-10-01  & 2014-11-01  & 2014-12-01  & 2014-09-30  \\ \hline
%\textbf{End Time}           & 2014-10-31  & 2014-10-31  & 2014-10-312 & 2014-12-29  & 2014-12-29  & 2014-12-29  & 2014-12-29  & 2014-12-29  & 2014-10-30  & 2014-11-29  & 2014-12-29  & 2014-12-29  \\ \hline
%\textbf{Devices$_{\control}$} & 3627                & 4033                & 3969                & 1266                & 3632                & 3852                & 3644                & 4277                & 11629               & 12394               & 13405               & 16015               \\ \hline
%\textbf{Devices$_{\test}$}    & 1481                & 1481                & 1481                & 1481                & 1481                & 1481                & 1481                & 1481                & 1481                & 1481                & 1481                & 1481                \\ \hline
%\end{tabular}
%\caption{Sanitized Dataset Description: Most of our analysis will be based on set$_{full}$ unless otherwise stated }
%\label{tab:sanitized-description}
%\end{table*}

%\todo{Table~\ref{tab:sanitized-description} turn it around}

%date\_service\_created & Service start (not used in our analysis)  \\ \hline
%service\_class\_name   & Used to differentiate data application    \\ \hline
%cmts\_inet             & Cmts identifier (derived from ip address) \\ \hline
%port\_name             & Cmts port descriptor                      \\ \hline
%device\_key            & not used in our analysis                  \\ \hline
%service\_identifier    & Service id (not used in our analysis)     \\ \hline


%\subsection{Data Processing}

% split database by direction, combine service class name
%To process the large amount of data (more than 15000 unique devices, 96 time 
%slots per day, 3 months, multiple service classes per time-slot), we first 
%split the data by direction into uplink and downlink. The nature of the 
%questions we ask in section~\ref{sec:intro} encourages us to concentrate on 
%the downstream data, although we present similar results for upstream data in 
%section~\ref{sec:results}. We also do not use the service class name 
%identifier in our analysis, which is internal to Comcast. \todo{Our analysis 
%showed that ignoring the service class identifier does not change our 
%conclusions on usage patterns and statistics.} Thus we only considered overall 
%usage for each gateway device in each time slot, in uplink and downlink 
%direction.



% remove weird dates with very low machines
%On exploring \control 4, we noticed that the dataset spanned the 
%October-December period, but for the first week there were 15000 unique 
%devices reporting their usage statistics, while after the first week, the 
%number dropped to 5000. Furthermore, \control 5 and \control 6 reported usage 
%for 5000 devices in the month of November, but only a 100 devices in December. 
%We did not want stray devices impacting our measure of availability, therefore 
%we sliced the \control datasets to monthly date ranges with a minimum of 4000, 
%or at least half the total unique devices present.
% why 4000? --- eyeballing availability plots -- 3k to 4k seemed to be the right 
%choice for control4

